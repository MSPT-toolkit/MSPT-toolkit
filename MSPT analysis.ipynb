{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24c1b241",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf214c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import trackpy\n",
    "import os\n",
    "import h5py\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import mspt.particle_fitting as fit\n",
    "import mspt.image_processing as img\n",
    "import mspt.particle_detection as detect\n",
    "import mspt.trajectory_analysis as traj\n",
    "import mspt.plotting as plot\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '32'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116bba14",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "`A` [**Movies to process (.MP)**](#moviestoprocess) <br/>\n",
    "\n",
    "`B` [**Movie processing**](#movieprocessing) <br/>\n",
    "&emsp;   1 [Parameter settings](#parametersettings) <br/>\n",
    "&emsp;   2 [Background removal, spot detection, and linking](#bgdetlink) <br/>\n",
    "&emsp;   3 [Alternatively, load already processed movies](#preprocessedmovies) <br/>\n",
    "&emsp;&emsp;   1 [Pre-processed movies to load](#loadpreprocessedmovies) <br/>\n",
    "&emsp;&emsp;   2 [Parameter settings](#parametersettings2) <br/>\n",
    "&emsp;&emsp;   3 [Spot detection and linking](#detlink) <br/>\n",
    "\n",
    "`C` [**Trajectory analysis**](#traj) <br/>\n",
    "&emsp;   1 [Parameter settings](#parametersettings3) <br/>\n",
    "&emsp;   2 [Files to process (.CSV)](#filestoprocess_csv) <br/>\n",
    "&emsp;   3 [Output file (.HDF5)](#outputfile) <br/>\n",
    "&emsp;   4 [Fit MSD and JDD](#fitmsdjdd) <br/>\n",
    "&emsp;   5 [Contrast-to-mass conversion](#contrasttomassconversion) <br/>\n",
    "&emsp;   6 [Estimate particle density on membrane](#particledensity) <br/>\n",
    "\n",
    "`D` [**Plotting**](#plotting) <br/>\n",
    "&emsp;   1 [Input HDF5 file](#hdf5file) <br/>\n",
    "&emsp;   2 [Load single data frame](#loaddata) <br/>\n",
    "&emsp;   3 [Alternatively, pool multiple data frames](#pooldata) <br/>\n",
    "&emsp;   4 [Generate correlation plot of mass and diffusion](#plotKDE) <br/>\n",
    "&emsp;   5 [Save figure to PDF](#savePDF) <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de5c963",
   "metadata": {},
   "source": [
    "# `A` Movies to process (.mp) <a name=\"moviestoprocess\"></a>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "|Input|Output|\n",
    "|:---|:---|\n",
    "|directory (str)| MP files (list)| \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b0274b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify directory\n",
    "#directory = os.path.normpath(r'C:\\Users\\admin\\Desktop\\MSPT test') # set manually\n",
    "directory = img.directoryDialog(os.getcwd()) # or via dialog\n",
    "\n",
    "# Generate list of .mp or .h5 files to process\n",
    "filepaths_data = img.find_filepaths(directory, extension='mp', exclude=None)\n",
    "for file in filepaths_data:\n",
    "    print(file)\n",
    "    \n",
    "assert len(filepaths_data) > 0, 'Cannot find any HDF5 files to process in current directory'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ffd85c",
   "metadata": {},
   "source": [
    "# `B` Movie processing <a name=\"movieprocessing\"></a>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<h4><center> Parameters </center></h4>\n",
    "\n",
    "|Load movie|Background removal|Spot detection|Trajectory linking|\n",
    "|:---|:---|:---|:---|\n",
    "|`batch_mode` (bool)  | `mode` (str)                  | `thresh` (float)     | `dmax` (float)| \n",
    "|`frame_range` (list) | `window_length` (int)         |`DoG_estimates` (dict)|`max_frames_to_vanish` (int)| \n",
    "|`navg` (int)         | `save_processed_movies` (bool)|                      | `minimum_trajectory_length` (int)| \n",
    "|                     | `parallel` (bool)             |                      | |\n",
    "|                     |`GPU` (bool)                   |                      | |\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "|Input|Output|\n",
    "|:---|:---|\n",
    "|MP files (list)| background-processed movie (HDF5 file)| \n",
    "|               | detection results (CSV file)| \n",
    "|               | linked trajectories (CSV file)| \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80b9464",
   "metadata": {},
   "source": [
    "## `B.1` Parameter settings <a name=\"parametersettings\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9036d66a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# General parameters\n",
    "batch_mode = True # Load mp file(s) on the fly without pop-up file dialog\n",
    "frame_range = [] # Restrict analysis to certain frames, e.g. [0, 2000]. To analyze whole movie, leave list empty.\n",
    "navg = 1 # Frame averaging, applied before background removal\n",
    "\n",
    "# Background removal\n",
    "mode = 'continuous_median' # Choose background removal strategy\n",
    "window_length = 1001 # Set median window length\n",
    "save_processed_movies = True # Save movies after background removal\n",
    "parallel = True # Use multiple cores to perform background substraction. Applies only if GPU=False\n",
    "GPU = False # Use GPU to perform background substraction (requires CUDA and pytorch). Applies only if parallel=False\n",
    "\n",
    "# Spot detection\n",
    "thresh = 0.00055 # Threshold paramter to mask candidate spots\n",
    "DoG_estimates={ 'T' : 0.1423, 's' : 2.1436, 'sigma' : 1.2921 } # Initial guesses for PSF fitting\n",
    "\n",
    "# Trajectory linking parameters\n",
    "dmax = 4. # Maximum displacement of particles per frame (in pixels)\n",
    "max_frames_to_vanish = 0 # Allow to link particles that where missed in these many frames\n",
    "minimum_trajectory_length = 5 # Only keep particle that exist for at least this many frames\n",
    "\n",
    "assert len(frame_range)==2 or len(frame_range)==0, 'frame_range is expected to be either of type [] or [int, int]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce32085",
   "metadata": {},
   "source": [
    "## `B.2` Background removal, spot detection, and linking <a name=\"bgdetlink\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9a552d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for filename in filepaths_data:\n",
    "    \n",
    "    # Apply continuous median background removal\n",
    "    frames, file = img.mp_reader(batch_mode=batch_mode,\n",
    "                                 file_to_load=filename,\n",
    "                                 frame_range=frame_range,\n",
    "                                 mode=mode,\n",
    "                                 navg=navg,\n",
    "                                 window_length=window_length,\n",
    "                                 parallel=parallel, \n",
    "                                 GPU=GPU)\n",
    "    \n",
    "    # Get name of video\n",
    "    name = os.path.splitext(os.path.basename(file))[0]\n",
    "    # Get current timestamp to prevent overwrite data\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # Save processed movies to HDF5 file\n",
    "    if save_processed_movies:\n",
    "        saving_folder_movie = os.path.splitext(file)[0] + '_{}{}'.format(mode[11:], window_length)\n",
    "        processed_movie_file = os.path.join(saving_folder_movie,\n",
    "                                            os.path.split(saving_folder_movie)[1] + '.h5')\n",
    "        \n",
    "        if not os.path.exists(saving_folder_movie):\n",
    "            os.makedirs(saving_folder_movie)\n",
    "        \n",
    "        with h5py.File(processed_movie_file, 'w') as fn:\n",
    "            fn.create_dataset('frames', data=frames)\n",
    "            fn.create_dataset('window_length', data=window_length)\n",
    "            if frame_range:\n",
    "                fn.create_dataset('frame_range', data=frame_range)\n",
    "            else:\n",
    "                fn.create_dataset('frame_range', data=[0, frames.shape[0]])\n",
    "        print('Saved processed movies to {}'.format(processed_movie_file))\n",
    "\n",
    "        \n",
    "    # Detect and fit candidate spots\n",
    "    fitted_particles = fit.particle_fitter(frames,\n",
    "                                           halfsize=window_length//2,\n",
    "                                           thresh=thresh,\n",
    "                                           frame_range=[],\n",
    "                                           method='trust-ncg',\n",
    "                                           DoG_estimates=DoG_estimates)     \n",
    "    \n",
    "    # Create folder to save processed data\n",
    "    if save_processed_movies:\n",
    "        detections_folder = os.path.join(saving_folder_movie,\n",
    "                                         'thresh{}_fits{}'.format(thresh, timestamp))\n",
    "    else:\n",
    "        detections_folder = '{}_{}{}_thresh{}_fits{}'.format(os.path.splitext(file)[0], # Remove file extension\n",
    "                                                             mode[11:], # Remove 'continuous_'\n",
    "                                                             window_length,\n",
    "                                                             thresh,\n",
    "                                                             timestamp)   \n",
    "        \n",
    "    if not os.path.exists(detections_folder):\n",
    "        os.makedirs(detections_folder)    \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    # Save particle detections as csv file\n",
    "    if len(frame_range) == 0:\n",
    "        csv_name = '{}_all_frames'.format(name)\n",
    "        detections_file = os.path.join(detections_folder,\n",
    "                                       csv_name + '.csv')  \n",
    "    else:\n",
    "        csv_name = '{}_frames{}-{}'.format(name, frame_range[0], frame_range[1])\n",
    "        detections_file = os.path.join(detections_folder,\n",
    "                                       csv_name + '.csv')\n",
    "    \n",
    "    fitted_particles.to_csv(detections_file)\n",
    "    print('Saved trajectory list to {}'.format(detections_file))\n",
    "\n",
    "    \n",
    "    # Link trajectories\n",
    "    linked_trajectories = trackpy.link_df(fitted_particles, search_range=dmax, memory=max_frames_to_vanish)\n",
    "    linked_trajectories = linked_trajectories.sort_values(by=['particle', 'frame'])\n",
    "    trajectories_lenfilt = trackpy.filter_stubs(linked_trajectories, minimum_trajectory_length)\n",
    "\n",
    "    trajectories_folder = os.path.join(detections_folder,\n",
    "                                       'dmax{}_mem{}_fits{}'.format(dmax, max_frames_to_vanish, timestamp))\n",
    "    \n",
    "    if not os.path.exists(trajectories_folder):\n",
    "        os.makedirs(trajectories_folder)\n",
    "\n",
    "    trajectories_file = os.path.join(trajectories_folder,\n",
    "                                     '{}_trajectories.csv'.format(csv_name))\n",
    "\n",
    "#     # Workaround in Windows if filename is too long\n",
    "#     if len(trajectories_file) >= 260: #max is 260\n",
    "#         trajectories_file = '\\\\\\\\?\\\\'+ trajectories_file\n",
    "\n",
    "    trajectories_lenfilt.to_csv(trajectories_file)\n",
    "    print('Saved trajectory list to {}'.format(trajectories_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ef6576",
   "metadata": {},
   "source": [
    "## `B.3` Alternatively, load already processed movies <a name=\"preprocessedmovies\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a6f6e4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h4><center> Parameters </center></h4>\n",
    "\n",
    "|Spot detection|Trajectory linking|\n",
    "|:---|:---|\n",
    "| `thresh` (float)     | `dmax` (float)| \n",
    "|`DoG_estimates` (dict)|`max_frames_to_vanish` (int)| \n",
    "|                      | `minimum_trajectory_length` (int)| \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "|Input|Output|\n",
    "|:---|:---|\n",
    "|HDF5 files (list)| detection results (CSV file)| \n",
    "|| linked trajectories (CSV file)| \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce5d6d9",
   "metadata": {},
   "source": [
    "### `B.3.1` Pre-processed movies to load <a name=\"loadpreprocessedmovies\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0048c1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify directory containing background-corrected movies\n",
    "#directory = os.path.normpath(r'C:\\Users\\admin\\Desktop\\MSPT example') # set manually\n",
    "directory = img.directoryDialog(os.getcwd()) # or via dialog\n",
    "\n",
    "# Generate list of .h5 files to process\n",
    "filepaths_data = img.find_filepaths(directory, extension='h5', exclude=None)\n",
    "for file in filepaths_data:\n",
    "    print(file)\n",
    "\n",
    "assert len(filepaths_data) > 0, 'Cannot find any HDF5 files to process in current directory'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6f3b88",
   "metadata": {},
   "source": [
    "### `B.3.2` Parameter settings <a name=\"parametersettings2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12618a22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analyze subset of saved movie\n",
    "frame_range = [] # Restrict analysis to certain frames, e.g. [0, 2000]. To analyze whole movie, leave list empty.\n",
    "\n",
    "# Spot detection\n",
    "thresh = 0.00055 # Threshold paramter to mask candidate spots\n",
    "DoG_estimates={ 'T' : 0.1423, 's' : 2.1436, 'sigma' : 1.2921 } # Initial guesses for PSF fitting\n",
    "\n",
    "# Trajectory linking parameters:\n",
    "dmax = 4. # Maximum displacement of particles per frame (in pixels)\n",
    "max_frames_to_vanish = 0 # Allow to link particles that where missed in these many frames\n",
    "minimum_trajectory_length = 5 # Only keep particle that exist for at least this many frames\n",
    "\n",
    "assert len(frame_range)==2 or len(frame_range)==0, 'frame_range is expected to be either of type [] or [int, int]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa94fd0c",
   "metadata": {},
   "source": [
    "### `B.3.3` Spot detection and linking <a name=\"detlink\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95be3d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for file in filepaths_data:\n",
    "    # Load processed movies from HDF5 file\n",
    "    with h5py.File(file, 'r') as h5_file:\n",
    "        frames = np.asarray(h5_file['frames']).copy()\n",
    "        window_length = np.asarray(h5_file['window_length']).copy()\n",
    "        frame_range_h5 = np.asarray(h5_file['frame_range']).copy()\n",
    "        if frame_range:\n",
    "            assert frame_range[0] >= frame_range_h5[0], 'Requested frame range not contained in processed movie'\n",
    "            assert frame_range[1] <= frame_range_h5[1], 'Requested frame range not contained in processed movie'\n",
    "            frames = frames[ frame_range[0]-frame_range_h5[0] : frame_range[1]-frame_range_h5[0] ]\n",
    "            \n",
    "    print('Loaded processed movie {}'.format(file))\n",
    "    \n",
    "    # Get name of video\n",
    "    name = os.path.splitext(os.path.basename(file))[0]\n",
    "    # Get current timestamp to prevent overwrite data\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "        \n",
    "    # Detect and fit candidate spots\n",
    "    fitted_particles = fit.particle_fitter(frames,\n",
    "                                           halfsize=window_length//2,\n",
    "                                           thresh=thresh,\n",
    "                                           method='trust-ncg',\n",
    "                                           DoG_estimates=DoG_estimates)     \n",
    "    \n",
    "    # Create folder to save processed data\n",
    "    saving_folder = os.path.dirname(file)\n",
    "    detections_folder = os.path.join(saving_folder,\n",
    "                                         'thresh{}_fits{}'.format(thresh, timestamp))\n",
    "        \n",
    "    if not os.path.exists(detections_folder):\n",
    "        os.makedirs(detections_folder)    \n",
    "\n",
    "\n",
    "    # Save particle detections as csv file\n",
    "    if len(frame_range) == 0:\n",
    "        csv_name = '{}_all_frames'.format(name)\n",
    "        detections_file = os.path.join(detections_folder,\n",
    "                                       csv_name + '.csv')  \n",
    "    else:\n",
    "        csv_name = '{}_frames{}-{}'.format(name, frame_range[0], frame_range[1])\n",
    "        detections_file = os.path.join(detections_folder,\n",
    "                                       csv_name + '.csv')\n",
    "    \n",
    "    fitted_particles.to_csv(detections_file)\n",
    "    print('Saved trajectory list to {}'.format(detections_file))\n",
    "\n",
    "    \n",
    "    # Link trajectories\n",
    "    linked_trajectories = trackpy.link_df(fitted_particles, search_range=dmax, memory=max_frames_to_vanish)\n",
    "    linked_trajectories = linked_trajectories.sort_values(by=['particle', 'frame'])\n",
    "    trajectories_lenfilt = trackpy.filter_stubs(linked_trajectories, minimum_trajectory_length)\n",
    "    \n",
    "    trajectories_folder = os.path.join(detections_folder,\n",
    "                                       'dmax{}_mem{}_fits{}'.format(dmax, max_frames_to_vanish, timestamp))\n",
    "    \n",
    "    if not os.path.exists(trajectories_folder):\n",
    "        os.makedirs(trajectories_folder)\n",
    "\n",
    "    trajectories_file = os.path.join(trajectories_folder,\n",
    "                                     '{}_trajectories.csv'.format(csv_name))\n",
    "\n",
    "#     # Workaround in Windows if filename is too long\n",
    "#     if len(trajectories_file) >= 260: #max is 260\n",
    "#         trajectories_file = '\\\\\\\\?\\\\'+ trajectories_file\n",
    "\n",
    "    trajectories_lenfilt.to_csv(trajectories_file)\n",
    "    print('Saved trajectory list to {}'.format(trajectories_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da166851",
   "metadata": {},
   "source": [
    "# `C` Trajectory analysis <a name=\"traj\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c40e087",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h4><center> Parameters </center></h4>\n",
    "\n",
    "|Movie acquisition|\n",
    "|:---|\n",
    "| `frame_rate` (float)| \n",
    "| `pixel_size` (float)|\n",
    "| `n_timelags_MSD` (int)|\n",
    "| `n_timelags_JDD` (int)|\n",
    "    \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "|Input|Output|\n",
    "|:---|:---|\n",
    "|CSV files (list)| analyzed trajectories (HDF5 file)| \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ec3dca",
   "metadata": {},
   "source": [
    "## `C.1` Parameter settings <a name=\"parametersettings3\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552b1e7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Movie acquisition parameters:\n",
    "frame_rate = 199.8 # in Hz\n",
    "pixel_size = 84.4 # in nm\n",
    "\n",
    "# JDD analysis\n",
    "n_timelags_MSD = None # Number of time lags to be used in MSD fitting. \n",
    "                      # If None, the optimal number of time lags is estimated.\n",
    "n_timelags_JDD = None # Number of time lags to be used in JDD fitting. \n",
    "                      # If None, the same number of time lags is considered as in MSD fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8420fc26",
   "metadata": {},
   "source": [
    "## `C.2` Files to process (.csv) <a name=\"filestoprocess_csv\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c36b9f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify directory with csv files\n",
    "#directory = os.path.normpath(r'C:\\Users\\admin\\Desktop\\MSPT results') # set manually\n",
    "directory = img.directoryDialog(os.getcwd()) # or via dialog\n",
    "assert os.path.isdir(directory), 'Directory \"{}\" does not exist'.format(directory)\n",
    "\n",
    "# Create list of csv files containing trajectories\n",
    "csv_files = traj.get_csv_files(directory)\n",
    "for file in csv_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dbc154",
   "metadata": {},
   "source": [
    "## `C.3` Output file (.hdf5) <a name=\"outputfile\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5cbb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify filename of the results file \n",
    "filename = 'MSPT result.h5'\n",
    "if os.path.isabs(filename):\n",
    "    results_file = filename\n",
    "else:\n",
    "    results_file = os.path.join(os.path.normpath(directory),filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0907276b",
   "metadata": {},
   "source": [
    "## `C.4` Fit mean squared displacement (MSD) and jump distance distribution (JDD) <a name=\"fitmsdjdd\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b93f9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit trajectories\n",
    "traj.fit_trajectories(csv_files,\n",
    "                      os.path.join(results_file),\n",
    "                      frame_rate=frame_rate,\n",
    "                      pixel_size=pixel_size,\n",
    "                      n_timelags_MSD=n_timelags_MSD,\n",
    "                      n_timelags_JDD=n_timelags_JDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65ae7a6",
   "metadata": {},
   "source": [
    "## `C.5` Contrast-to-mass conversion <a name=\"contrasttomassconversion\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd203f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Microscope-specific calibration parameters\n",
    "slope = 28191.37194436 # in kDa/'contrast'\n",
    "offset = -20.47852753 # in kDa\n",
    "\n",
    "# Load HDF5 file where results of the trajectory analysis are stored\n",
    "# Convert contrast to mass using the linear relationship obtained from calibration measurements\n",
    "with pd.HDFStore(results_file, 'r+') as dfs:\n",
    "    for idx, key in enumerate(dfs.keys()):\n",
    "        print('Processing DataFrame {}/{}...'.format(idx+1,len(dfs.keys())))\n",
    "        df = dfs[key].copy()\n",
    "        #df['median_mass'] = slope * df['med_c'] + offset\n",
    "        df['median_mass'] = traj.apply_calibration(df, slope=slope, offset=offset)\n",
    "        dfs[key] = df.copy()\n",
    "        \n",
    "print('Added column \"median_mass\" to each DataFrame in the HDF5 container {}'.format(results_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf5ba0f",
   "metadata": {},
   "source": [
    "## `C.6` Estimate particle density on membrane <a name=\"particledensity\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88cf682",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load HDF5 file where results of the trajectory analysis are stored\n",
    "# Calculate the number of particles present for each trajectory 'particle number (linked)'\n",
    "with pd.HDFStore(results_file, 'r+') as dfs:\n",
    "    for idx, key in enumerate(dfs.keys()):\n",
    "        print('Processing DataFrame {}/{}...'.format(idx+1,len(dfs.keys())))\n",
    "        df = dfs[key].copy()\n",
    "        df['particle number (linked)'] = traj.calc_particle_number_linked(df)\n",
    "        df['particle number (detected)'] = traj.calc_particle_number_detected(df, key)\n",
    "        dfs[key] = df.copy()\n",
    "        \n",
    "print('Added column \"particle number (linked)\" and \"particle number (detected)\" to each DataFrame in the HDF5 container {}'.format(results_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8ef39b",
   "metadata": {},
   "source": [
    "# `D` Plotting <a name=\"plotting\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab713f63",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h4><center> Plotting parameters </center></h4>\n",
    "\n",
    "|X variable|Y variable| Axis limits | Filter trajectories |Misc\n",
    "|:---|:---|:---|:---|:---|\n",
    "|`median_mass`| `Deff_global` | `x_range` | `traj_length` | `figsize`  |\n",
    "|`mean_mass`  | `Deff_JDD`    | `y_range` | `density`     | `n_levels` |\n",
    "|`med_c`      | `D_MSD_n4`    |           |               | `cmap`     |\n",
    "|`mean_c`     |               |           |               | `alpha`    |\n",
    "|             |               |           |               | `show`     |\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "|Input|Output|\n",
    "|:---|:---|\n",
    "|MSPT results (DataFrame)| 2D-KDE plot (mpl figure/PDF)| \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3ae945",
   "metadata": {},
   "source": [
    "## `D.1` Input HDF5 file <a name=\"hdf5file\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bf11fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify HDF5 file containing MSPT results\n",
    "#results_file = os.path.normpath(r\"C:\\Users\\admin\\Desktop\\MSPT test\\MSPT result.h5\") # set manually\n",
    "results_file = img.fileDialog(os.getcwd()) # or via file dialog\n",
    "assert os.path.isfile(results_file), 'File \"{}\" does not exist'.format(results_file)\n",
    "\n",
    "# Load data containers into memory as a dictionary\n",
    "data = dict()\n",
    "with pd.HDFStore(results_file, 'r') as dfs:\n",
    "    for key in dfs.keys():\n",
    "        data[key] = dfs[key].copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f592b097",
   "metadata": {},
   "source": [
    "## `D.2` Load single data frame <a name=\"loaddata\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e965fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load single DataFrame\n",
    "data_set_index = 0 # Specify data set index\n",
    "key = list(data.keys())[data_set_index] # keys are trajectory CSV filenames\n",
    "data_single = data[key].copy() # Load single DataFrame\n",
    "print(data_single.shape)\n",
    "print(data_single.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9db044f",
   "metadata": {},
   "source": [
    "## `D.3` Alternatively, pool multiple data frames <a name=\"pooldata\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7e9117",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Pool data to get a single DataFrame\n",
    "data_pooled = pd.concat(data,axis=0)\n",
    "print(data_pooled.shape)\n",
    "print(data_pooled.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0048894e",
   "metadata": {},
   "source": [
    "## `D.4` Generate correlation plot of mass and diffusion <a name=\"plotKDE\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e05935",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot data\n",
    "fig, axs, df_kde, dat = plot.generate_2D_KDE(data_pooled,\n",
    "                                             x='median_mass',\n",
    "                                             y='Deff_MSD_JDD',\n",
    "                                             x_range=(0,400), \n",
    "                                             y_range=(-1,1), # in log space\n",
    "                                             figsize=(5,5),\n",
    "                                             traj_length=5,\n",
    "                                             density=None,\n",
    "                                             n_levels=12,\n",
    "                                             cmap=mpl.cm.gray_r,\n",
    "                                             alpha=1.0,\n",
    "                                             show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5622725d",
   "metadata": {},
   "source": [
    "## `D.5` Save figure to PDF <a name=\"savePDF\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf065cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save plot to pdf\n",
    "fig.savefig(r\"C:\\Users\\admin\\Desktop\\JoVE Aldolase\\MSPT_results_pooled.pdf\", transparent=True, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
